{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network for Detect Mask Type V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEmzmtNqxvrv"
      },
      "source": [
        "# Convolutional Neural Network dengan PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-P0mPxZLVG8"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Menggunakan library dari google colab, kami bisa menghubungkan langsung dari shared google drive ke google colab ini. Proses ini sangat menghemat waktu karna tidak perlu upload berulang setiap memulai runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52TWTrUjlc7b"
      },
      "source": [
        "Sumber dataset ada tiga yaitu instagram, google image, dan foto sendiri. \r\n",
        "- Untuk yang dari instagram memiliki format penamaan (username ig)-(tanggal didownload)-(file keberapa)\r\n",
        "- Untuk yang foto sendiri penamaan mengikuti format dari HP, umumnya penamaan file diawali photos... atau FILE...\r\n",
        "- Sisanya adalah penamaan yang tak beraturan bersumber dari google images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avhBIhiszpri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e58c29a-bcc5-4e91-a0a5-8584b53b4753"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eiG6id4LRsd"
      },
      "source": [
        "### Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TnOKvJhxyuL"
      },
      "source": [
        "import torch as pt # library utama pytorch\n",
        "import numpy as np # numerical python\n",
        "import pandas as pd # bermain dataset\n",
        "import copy # untuk copy2 an\n",
        "\n",
        "# libray lain pytorch untuk membangun arsitektur\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "\n",
        "# library dar pytorch untuk pengelolaan dataset khususnya data citra\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsK_3FRxWWhy"
      },
      "source": [
        "### Preprocessing\n",
        "Pada bagian ini kita akan memperbaiki data agar enak dibaca CNN\n",
        "\n",
        "Input CNN sebesar 244x244, maka agar tidak kehilangan informasi, foto di resize menjadi 256 lalu di centre crop sebesar 224x224."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39bNbUzGLPHN"
      },
      "source": [
        "train_dir = \"/content/gdrive/Shareddrives/Tubes DL/Train\"\n",
        "test_dir = \"/content/gdrive/Shareddrives/Tubes DL/Test\"\n",
        "\n",
        "# fungsi transform bertugas untuk \"mengedit\" data yang masuk\n",
        "# macam-macam perintah yang bisa dilakukan bisa cek di sini: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "train_transform = transforms.Compose([ # proses transform dilakukan secara berurutan\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(), # 2. di ubah ke tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256), \n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# load dataset dengan format folder yang sesuai lalu aplikasikan transformasi ke data yang dibaca\n",
        "# hasil dari proses ini adalah sebuah list berelemen tuple (tensor_citra, label) disebut dengan objek datasets\n",
        "train_img = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "test_img = datasets.ImageFolder(test_dir, transform=test_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQBKK-lInyHo"
      },
      "source": [
        "trainloaders = pt.utils.data.DataLoader(train_img, batch_size=16, shuffle=True)\n",
        "testloaders = pt.utils.data.DataLoader(test_img, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nzq8eMRWSgQ",
        "outputId": "2246d534-20cf-4394-9da7-3dadaf06acb1"
      },
      "source": [
        "# Informasi dari dataset kita\n",
        "print(\"train_img type   :\",type(train_img)) # objek datasets\n",
        "\n",
        "print(\"train_img length :\",len(train_img)) # 515 data train\n",
        "print(\"test_img length :\",len(test_img)) # 66 data test\n",
        "\n",
        "print(\"train_img classes:\",train_img.classes) # nama kelas\n",
        "print(\"train_img classes:\",train_img.class_to_idx) # nama kelas\n",
        "\n",
        "print(\"train_img[0] type:\",type(train_img[0])) # tuple (A, B)\n",
        "print(\"train_img[0][0]  :\",train_img[0][0].size()) # tensor citra\n",
        "print(\"train_img[0][1]  :\",train_img[0][1]) # label\n",
        "\n",
        "# variabel banyak data\n",
        "len_train = len(train_img)\n",
        "len_test = len(test_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_img type   : torchvision.datasets.folder.ImageFolder\n",
            "train_img length : 477\n",
            "test_img length : 90\n",
            "train_img classes: ['KAIN', 'MEDIS', 'SCUBA']\n",
            "train_img classes: {'KAIN': 0, 'MEDIS': 1, 'SCUBA': 2}\n",
            "train_img[0] type: <class 'tuple'>\n",
            "train_img[0][0]  : torch.Size([3, 224, 224])\n",
            "train_img[0][1]  : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UssQHHz7j-_J"
      },
      "source": [
        "### Buat Arsitektur\r\n",
        "Arsitektur menggunakan pre-trained model residual networks dengan model structure resnet50 karena errornya tidak jauh berbeda dengan resnet152 namun size file pth yang dihasilkan relatif kecil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rchiu6a-V4y7",
        "outputId": "af7050ce-32aa-49d0-b7a2-c70cee72da89"
      },
      "source": [
        "modelkita = models.resnet50(pretrained=True)\n",
        "\n",
        "#freezing\n",
        "for param in modelkita.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# hapus layer terakhir\n",
        "modelkita.fc = nn.Linear(2048, 3) #2048 dilihat dari jumlah layer kedua sebelum terakhir\n",
        "\n",
        "modelkita = modelkita.cuda()\n",
        "print(modelkita)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLKs_GA8lpga"
      },
      "source": [
        "optimizer = pt.optim.Adagrad(modelkita.parameters(), lr=0.01) # algoritma training\n",
        "criterion = nn.CrossEntropyLoss() # rumus error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJF4Ohf7nGUD"
      },
      "source": [
        "### Mulai Training\r\n",
        "\r\n",
        "Agar tidak overfitting, kami memilih menggunakan 25 epoch, berhenti sebelum akurasi train mencapai 90% "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaxfFPyWmcz2",
        "outputId": "e6b5fffe-8a6f-4ee7-fbd7-28056ff7c3e5"
      },
      "source": [
        "modelkita.train()\n",
        "for i in range(25): # 25 epoch\n",
        "\n",
        "    rata2error = 0 # untuk menghitung error (\"seberapa salah\")\n",
        "    jumlahbenar = 0 # untuk menghitung akurasi (\"seberapa benar\")\n",
        "\n",
        "    for image, label in trainloaders: # iterasi semua data\n",
        "        \n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "        # forward\n",
        "        Y = modelkita( image )\n",
        "        E = criterion( Y, label )\n",
        "        rata2error += E\n",
        "\n",
        "        prediksi = pt.max(Y, dim=1).indices\n",
        "        for i in range(len(prediksi)):\n",
        "            if prediksi[i]==label[i]:\n",
        "                jumlahbenar+=1\n",
        "        \n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        E.backward()       \n",
        "\n",
        "        # update\n",
        "        optimizer.step() \n",
        "\n",
        "    print(rata2error/len_train, jumlahbenar/len_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>) 0.5471698113207547\n",
            "tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>) 0.6876310272536688\n",
            "tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>) 0.7526205450733753\n",
            "tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>) 0.7924528301886793\n",
            "tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>) 0.7945492662473794\n",
            "tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>) 0.80083857442348\n",
            "tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>) 0.8155136268343816\n",
            "tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>) 0.8301886792452831\n",
            "tensor(0.0269, device='cuda:0', grad_fn=<DivBackward0>) 0.8427672955974843\n",
            "tensor(0.0264, device='cuda:0', grad_fn=<DivBackward0>) 0.8469601677148847\n",
            "tensor(0.0261, device='cuda:0', grad_fn=<DivBackward0>) 0.8553459119496856\n",
            "tensor(0.0255, device='cuda:0', grad_fn=<DivBackward0>) 0.8616352201257862\n",
            "tensor(0.0252, device='cuda:0', grad_fn=<DivBackward0>) 0.8511530398322851\n",
            "tensor(0.0250, device='cuda:0', grad_fn=<DivBackward0>) 0.8616352201257862\n",
            "tensor(0.0246, device='cuda:0', grad_fn=<DivBackward0>) 0.8574423480083857\n",
            "tensor(0.0224, device='cuda:0', grad_fn=<DivBackward0>) 0.8742138364779874\n",
            "tensor(0.0236, device='cuda:0', grad_fn=<DivBackward0>) 0.8553459119496856\n",
            "tensor(0.0231, device='cuda:0', grad_fn=<DivBackward0>) 0.8784067085953878\n",
            "tensor(0.0214, device='cuda:0', grad_fn=<DivBackward0>) 0.8867924528301887\n",
            "tensor(0.0228, device='cuda:0', grad_fn=<DivBackward0>) 0.8805031446540881\n",
            "tensor(0.0234, device='cuda:0', grad_fn=<DivBackward0>) 0.8637316561844863\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<DivBackward0>) 0.8846960167714885\n",
            "tensor(0.0206, device='cuda:0', grad_fn=<DivBackward0>) 0.8909853249475891\n",
            "tensor(0.0197, device='cuda:0', grad_fn=<DivBackward0>) 0.8951781970649895\n",
            "tensor(0.0203, device='cuda:0', grad_fn=<DivBackward0>) 0.8846960167714885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srVykYJAyySw"
      },
      "source": [
        "### Testing\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LRi8G0My0nO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94df850-d787-4dc7-a9e5-ba9a380d6d1d"
      },
      "source": [
        "modelkita.eval()\n",
        "\n",
        "with pt.no_grad():\n",
        "    rata2error = 0 # untuk menghitung error (\"seberapa salah\")\n",
        "    jumlahbenar = 0 # untuk menghitung akurasi (\"seberapa benar\")\n",
        "\n",
        "    for image, label in testloaders: # iterasi semua data\n",
        "        \n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "        # forward\n",
        "        Y = modelkita( image )\n",
        "        E = criterion( Y, label )\n",
        "        rata2error += E\n",
        "\n",
        "        prediksi = pt.max(Y, dim=1).indices\n",
        "        for i in range(len(prediksi)):\n",
        "            if prediksi[i]==label[i]:\n",
        "                jumlahbenar+=1\n",
        "\n",
        "    print(rata2error/len_test, jumlahbenar/len_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.3460, device='cuda:0') 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMtnaVo0xysL"
      },
      "source": [
        "### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE1sCdIfx1Jg"
      },
      "source": [
        "pt.save(modelkita, \"modelkita_88_90.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9u3aiQ2tdOR"
      },
      "source": [
        "#### Copy model ke Shared Drive\r\n",
        "\r\n",
        "File pth terbilang cukup besar, butuh banyak waktu untuk download dan upload ke shared drive agar bisa digunakan bersama teman kelompok yang lain, maka dari itu kami menggunakan command cp (command linux) untuk meng-copy files dari collab langsung ke google drive\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQEj68z_siyK"
      },
      "source": [
        "!cp \"/content/modelkita_88_90.pth\" \"/content/gdrive/Shareddrives/Tubes DL\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}